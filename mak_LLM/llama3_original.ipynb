{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbeb0ff-ef58-4a17-a9ea-37613aee6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction to SageMaker JumpStart - Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e567a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e36b9",
   "metadata": {},
   "source": [
    "In this demo notebook, we demonstrate how to use the SageMaker Python SDK to deploy a SageMaker JumpStart text generation model and invoke the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af77efb",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, upgrade to the latest sagemaker SDK to ensure all available models are deployable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b05b931-992e-4526-978d-f03196874a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb6b35",
   "metadata": {},
   "source": [
    "Select the desired model to deploy. The provided dropdown filters all text generation models available in SageMaker JumpStart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f625a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-textgeneration-llama-3-8b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a40df34",
   "metadata": {
    "jumpStartAlterations": [
     "modelIdOnly"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "accept_eula = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a0388",
   "metadata": {},
   "source": [
    "## Deploy model\n",
    "\n",
    "Create a `JumpStartModel` object, which initializes default model configurations conditioned on the selected instance type. JumpStart already sets a default instance type, but you can deploy the model on other instance types by passing `instance_type` to the `JumpStartModel` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a2a8e5-789f-4041-9927-221257126653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-3-8b-instruct' with wildcard version identifier '*'. You can pin to version '2.2.1' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "model = JumpStartModel(model_id=model_id, instance_type=\"ml.g5.2xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259ad4f",
   "metadata": {},
   "source": [
    "You can now deploy the model using SageMaker JumpStart. If the selected model is gated, you will need to accept the end-user license agreement (EULA) prior to deployment. This is accomplished by providing the `accept_eula=True` argument to the `deploy` method. The deployment might take few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3b42ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(accept_eula=accept_eula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10cf06c",
   "metadata": {},
   "source": [
    "## Invoke the endpoint\n",
    "\n",
    "This section demonstrates how to invoke the endpoint using example payloads that are retrieved programmatically from the `JumpStartModel` object. You can replace these example payloads with your own payloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb364d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_payloads = model.retrieve_all_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5899c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " {'inputs': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nwhat is the recipe of mayonnaise?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.6, 'details': True, 'stop': '<|eot_id|>'}}\n",
      "\n",
      "Output:\n",
      " The classic condiment! Mayonnaise is a thick, creamy sauce made from a combination of oil, egg yolks, acid (such as vinegar or lemon juice), and seasonings. Here's a simple recipe to make mayonnaise at home:\n",
      "\n",
      "**Ingredients:**\n",
      "\n",
      "* 2 egg yolks\n",
      "* 1 tablespoon lemon juice or vinegar (such as apple cider vinegar or white wine vinegar)\n",
      "* 1/2 teaspoon Dijon mustard (optional, but recommended for flavor)\n",
      "* 1/2 cup (120 ml) neutral-tasting oil, such as canola, grapeseed, or sunflower oil\n",
      "* Salt, to taste\n",
      "* Water, as needed\n",
      "\n",
      "**Instructions:**\n",
      "\n",
      "1. **Start with room temperature ingredients**: Make sure your egg yolks, lemon juice, and oil are at room temperature. This will help the mixture emulsify smoothly.\n",
      "2. **Whisk the egg yolks**: In a medium-sized bowl, whisk together the egg yolks and lemon juice until well combined.\n",
      "3. **Add the mustard (if using)**: Whisk in the Dijon mustard, if using.\n",
      "4. **Slowly add the oil**: While continuously whisking the egg yolk mixture, slowly pour in the oil\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nI am going to Paris, what should I see?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nParis, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:\\n\\n1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.\\n2. The Louvre Museum: The Louvre is one of the world's largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.\\n3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.\\n\\nThese are just a few of the many attractions that Paris has to offer. With so much to see and do, it's no wonder that Paris is one of the most popular tourist destinations in the world.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is so great about #1?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.6, 'stop': '<|eot_id|>'}}\n",
      "\n",
      "Output:\n",
      " The Eiffel Tower! It's an iconic symbol of Paris and one of the most recognizable landmarks in the world. Here are some reasons why it's so great:\n",
      "\n",
      "1. **Engineering marvel**: The Eiffel Tower was the tallest structure in the world when it was built for the 1889 World's Fair, and it's still an impressive feat of engineering. It's made of over 18,000 pieces of wrought iron and stands 324 meters (1,063 feet) tall.\n",
      "2. **Panoramic views**: The Eiffel Tower offers breathtaking views of the city from its observation decks, which are 57 meters (187 feet) and 115 meters (377 feet) above ground. On a clear day, you can see for miles in every direction.\n",
      "3. **Romantic atmosphere**: The Eiffel Tower is often associated with romance, and it's a popular spot for couples to propose, get married, or simply enjoy a romantic dinner at one of the many restaurants with a view.\n",
      "4. **History**: The Eiffel Tower has played a significant role in French history, serving as a symbol of French culture and engineering prowess. It's also been the site of many famous events, including the first radio broadcast and the first\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nAlways answer with Haiku<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nI am going to Paris, what should I see?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.6, 'stop': '<|eot_id|>'}}\n",
      "\n",
      "Output:\n",
      " Eiffel Tower high\n",
      "River Seine's gentle whispers\n",
      "Art and love abound\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nAlways answer with emojis<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow to go from Beijing to NY?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.6, 'stop': '<|eot_id|>'}}\n",
      "\n",
      "Output:\n",
      " üõ´Ô∏èüóºÔ∏èüõ¨\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for payload in example_payloads:\n",
    "    response = predictor.predict(payload.body)\n",
    "    response = response[0] if isinstance(response, list) else response\n",
    "    print(\"Input:\\n\", payload.body, end=\"\\n\\n\")\n",
    "    print(\"Output:\\n\", response[\"generated_text\"].strip(), end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd54758-3149-431f-a5f8-2a744de9f8a4",
   "metadata": {},
   "source": [
    "# BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e9725b-bcd4-4524-b91b-6c31acbc04dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.4)\n",
      "Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-2.10.1 sacrebleu-2.4.2\n",
      "sacrebleu 2.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk sacrebleu\n",
    "!sacrebleu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f27196dd-255b-436f-8388-f5d0c336a2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score (): 100.00000000000004\n",
      "BLEU = 100.00 100.0/100.0/100.0/100.0 (BP = 1.000 ratio = 1.000 hyp_len = 35 ref_len = 35)\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "# ÂèÇËÄÉÊñáÊú¨ÔºàÂ≠óÁ¨¶‰∏≤Ôºâ\n",
    "reference_text = \"The patient is referred due to the rapid progression of the tumor despite initial treatment modalities. Further evaluation and management from a specialized neuro-oncology team are essential for this recurrent and aggressive tumor.\"\n",
    "\n",
    "# ÁîüÊàêÁöÑÊñáÊú¨ÔºàÂ≠óÁ¨¶‰∏≤Ôºâ\n",
    "candidate_text = \"The patient is referred due to the rapid progression of the tumor despite initial treatment modalities. Further evaluation and management from a specialized neuro-oncology team are essential for this recurrent and aggressive tumor.\"\n",
    "\n",
    "# ËÆ°ÁÆóBLEUÂàÜÊï∞ÔºåË∞ÉÊï¥n-gramÊùÉÈáç\n",
    "# ÈªòËÆ§ÊùÉÈáçÊòØ(0.25, 0.25, 0.25, 0.25)ÔºåÂàÜÂà´ÂØπÂ∫î1-gramÂà∞4-gram\n",
    "# Êàë‰ª¨ÂèØ‰ª•Ë∞ÉÊï¥ÊùÉÈáçÔºå‰æãÂ¶ÇÂè™ËÄÉËôë1-gramÂíå2-gramÔºåÊùÉÈáçÂàÜÂà´‰∏∫(0.5, 0.5)\n",
    "# ËÆæÁΩÆn-gramÊùÉÈáç\n",
    "weights = (0.5, 0.5, 0, 0)\n",
    "\n",
    "# ÂàõÂª∫BLEUÂØπË±°ÔºåÂπ∂‰º†ÂÖ•Ëá™ÂÆö‰πâÁöÑÊùÉÈáç\n",
    "weights = (0.5, 0.5, 0, 0)\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu([candidate_text], [[reference_text]])\n",
    "print(f\"BLEU score (): {bleu.score}\")\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be65b3e-6354-45f7-849e-d277ae77fbbb",
   "metadata": {},
   "source": [
    "# ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc4108c7-4bab-4bda-9184-9cbbfc1cff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22fe5af6-41a4-4b8c-97d0-469c19fece6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores: {'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# ËÆ°ÁÆóROUGEÂàÜÊï∞\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(candidate_text, reference_text, avg=True) # Áî±‰∫éÂè™Êúâ‰∏Ä‰∏™ referenceÔºåÊâÄ‰ª• avgÊ≤°ÊúâÂΩ±Âìç\n",
    "print(f\"ROUGE scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c07884a-5b0f-4821-9e90-73b1404b0ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " Output:\n",
      "{\n",
      "\"is_Papilledema\": False,\n",
      "\"referral_content\": \"Kindly see him for a specialist evaluation to determine the best course of action. I believe a more intensive investigation, including possibly imaging and more advanced pulmonary function tests, might be necessary.\"\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"letter.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    letter = f.read()\n",
    "# print(letter)\n",
    "\n",
    "response = predictor.predict({'inputs': letter,\n",
    "                             'parameters': {'max_new_tokens': 128}})\n",
    "response = response[0] if isinstance(response, list) else response\n",
    "\n",
    "print(\"Output:\\n\", response[\"generated_text\"].strip(), end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffbba033-649a-4c86-a611-5c625b55b214",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test all test.json with llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78baba8-ff22-49a6-b561-9ba7aa58729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "from rouge import Rouge\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "def replace_output_prefix(input_str):\n",
    "    # ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèËøõË°åÊõøÊç¢ÔºåÂøΩÁï•Â§ßÂ∞èÂÜô\n",
    "    result = re.sub(r'(?i)^Output:\\s*', '', input_str)\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_braced_content(input_str):\n",
    "    # ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÊèêÂèñÂ§ßÊã¨Âè∑ÂèäÂÖ∂ÂÜÖÁöÑÂÜÖÂÆπ\n",
    "    match = re.search(r'\\{[^{}]*\\}', input_str)\n",
    "    if match:\n",
    "        # ËøîÂõûÂåÖÂê´Â§ßÊã¨Âè∑ÂèäÂÖ∂ÂÜÖÂÆπÁöÑÂåπÈÖçÈÉ®ÂàÜ\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        # Â¶ÇÊûúÊ≤°ÊúâÂåπÈÖçÂà∞ÂÜÖÂÆπÔºåËøîÂõûÁ©∫Â≠óÁ¨¶‰∏≤ÊàñÂÖ∂‰ªñÊ†áËÆ∞\n",
    "        return ''\n",
    "\n",
    "\n",
    "def extract_referral_content(data_str):\n",
    "    # ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÊèêÂèñreferral_contentÁöÑÂÜÖÂÆπ\n",
    "    match = re.search(r'\"referral_content\":\\s*(null|\".*?\")', data_str)\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        if content == \"null\":\n",
    "            return \"\"\n",
    "        else:\n",
    "            # ÂéªÊéâÂºïÂè∑\n",
    "            return content.strip('\"')\n",
    "    return ''\n",
    "\n",
    "\n",
    "def evaluate_jsonl_with_llama3(predictor, path, csv_file_path):\n",
    "    test_data_json = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            test_data_json.append(json.loads(line.strip()))\n",
    "    rouge_score_list = []\n",
    "    bleu_score_list = []\n",
    "\n",
    "    rouge = Rouge()\n",
    "\n",
    "    evaluate_list = []\n",
    "\n",
    "    for single_test in test_data_json:\n",
    "        instruction = single_test[\"instruction\"]\n",
    "        whole_letter = single_test[\"whole_letter\"]\n",
    "        referral_content = single_test[\"referral_content\"]\n",
    "        prompt = f\"{instruction}\\n\\n###\\n\\n{whole_letter}\\n\\n###\"\n",
    "        response = predictor.predict({'inputs': prompt, 'parameters': {'max_new_tokens': 128}})\n",
    "        # print(prompt)\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "\n",
    "        response = response[0] if isinstance(response, list) else response\n",
    "        # print(\"Output:\\n\", response[\"generated_text\"].strip(), end=\"\\n\\n\\n\")\n",
    "\n",
    "        reference_text = referral_content\n",
    "        # try:\n",
    "        tmp_str = replace_output_prefix(response[\"generated_text\"].strip())\n",
    "        print(tmp_str)\n",
    "#             tmp_str = extract_braced_content(tmp_str)\n",
    "#             # print(tmp_str)\n",
    "#             tmp = extract_referral_content(tmp_str)\n",
    "#             candidate_text = tmp\n",
    "#         except Exception as err:\n",
    "#             # print(single_test[\"id\"])\n",
    "#             # print(response[\"generated_text\"].strip())\n",
    "#             # print()\n",
    "#             candidate_text = \"extract failure\"\n",
    "#         finally:\n",
    "\n",
    "#             evaluate_list.append(candidate_text)\n",
    "#             print(\"predict: \" + candidate_text)\n",
    "#             print(\"real: \" + reference_text)\n",
    "\n",
    "\n",
    "#             bleu = sacrebleu.corpus_bleu([candidate_text], [[reference_text]])\n",
    "#             bleu_score_list.append(bleu.score)\n",
    "#             print(bleu.score)\n",
    "#             single_test[\"bleu\"] = bleu.score\n",
    "#             single_test[\"predict_referral_content\"] = candidate_text\n",
    "#             print()\n",
    "#             # ËÆ°ÁÆóROUGEÂàÜÊï∞\n",
    "#             # scores = rouge.get_scores(candidate_text, reference_text) # Áî±‰∫éÂè™Êúâ‰∏Ä‰∏™ referenceÔºåÊâÄ‰ª• avgÊ≤°ÊúâÂΩ±Âìç\n",
    "#             # rouge_score_list.append(scores)\n",
    "            \n",
    "# #     with open(output_jsonl_path, mode='w', encoding='utf-8') as f:\n",
    "# #         for single_test in test_data_json:\n",
    "# #             f.write(json.dumps(single_test, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# #     print(f\"predicted data has been saved to {output_path}.\")\n",
    "    \n",
    "#     # ÂàõÂª∫ CSV Êñá‰ª∂\n",
    "#     csv_data = []\n",
    "\n",
    "#     for single_test in test_data_json:\n",
    "#         csv_data.append({\n",
    "#             # \"id\": single_test[\"id\"],\n",
    "#             # \"name\": single_test[\"name\"],\n",
    "#             \"instruction\": single_test[\"instruction\"],\n",
    "#             \"whole_letter\": single_test[\"whole_letter\"],\n",
    "#             \"referral_content\": single_test[\"referral_content\"],\n",
    "#             \"predict_referral_content\": single_test[\"predict_referral_content\"],\n",
    "#             \"bleu\": single_test[\"bleu\"],\n",
    "#         })\n",
    "\n",
    "#     # ÂàõÂª∫ DataFrame\n",
    "#     df = pd.DataFrame(csv_data)\n",
    "\n",
    "#     # ‰øùÂ≠ò‰∏∫ CSV Êñá‰ª∂\n",
    "#     df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "#     print(f\"CSV file has been saved to {csv_file_path}\")\n",
    "    \n",
    "#     return evaluate_list, bleu_score_list, rouge_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cb857-02cd-4f66-8d5d-51c448d0e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluate_list, test_bleu_score_list, test_rouge_score_list = evaluate_jsonl_with_llama3(predictor, \"test_data_735/test.jsonl\", \"llama3_original_test_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a53e57",
   "metadata": {},
   "source": [
    "## Clean up the endpoint\n",
    "Don't forget to clean up resources when finished to avoid unnecessary charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35117832-710d-4308-91f0-a33da723a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_predict_data(bleu_score_list):\n",
    "    # ÁªüËÆ°Â§ß‰∫é100ÁöÑ‰∏™Êï∞\n",
    "    count_gt_100 = sum(1 for score in bleu_score_list if score >= 100)\n",
    "\n",
    "    # ÁªüËÆ°Â§ß‰∫é70ÁöÑ‰∏™Êï∞\n",
    "    count_gt_70 = sum(1 for score in bleu_score_list if score > 70)\n",
    "\n",
    "    prob_gt_100 = count_gt_100 / len(bleu_score_list)\n",
    "    prob_gt_70 = count_gt_70 / len(bleu_score_list)\n",
    "    average_score = sum(bleu_score_list) / float(len(bleu_score_list))\n",
    "\n",
    "    print(f\"ÂàÜÊï∞Â§ß‰∫é100ÁöÑ‰∏™Êï∞Ôºö{count_gt_100}, Âç†ÊâÄÊúâÊï∞ÊçÆÁöÑÁôæÂàÜÊØî‰∏∫Ôºö {prob_gt_100}\")\n",
    "    print(f\"ÂàÜÊï∞Â§ß‰∫é70ÁöÑ‰∏™Êï∞Ôºö{count_gt_70}, Âç†ÊâÄÊúâÊï∞ÊçÆÁöÑÁôæÂàÜÊØî‰∏∫Ôºö {prob_gt_70}\")\n",
    "    print(f\"bleuÂπ≥ÂùáÂàÜÊï∞: {average_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bb2ce-9e05-49d8-970b-5d3cfc41a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_predict_data(test_bleu_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4998b86",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|jumpstart-text-generation-inference.ipynb)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
